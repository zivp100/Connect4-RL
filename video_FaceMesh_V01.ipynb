{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video-FaceMesh-V01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOE6tZYIvweRXZI5WRUpG8R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zivp100/Connect4-RL/blob/master/video_FaceMesh_V01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.3\n",
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "cVaZLvjFYvyb",
        "outputId": "d954fc7b-fc35-4e25-f1f6-b25d5ac8cb92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.19.3\n",
            "  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 8.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.3 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.8.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.9 MB 265 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.8.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import os\n",
        "\n",
        "def video_to_frames(input_loc, output_loc):\n",
        "    \"\"\"Function to extract frames from input video file\n",
        "    and save them as separate frames in an output directory.\n",
        "    Args:\n",
        "        input_loc: Input video file.\n",
        "        output_loc: Output directory to save the frames.\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        os.mkdir(output_loc)\n",
        "    except OSError:\n",
        "        pass\n",
        "    # Log the time\n",
        "    time_start = time.time()\n",
        "    # Start capturing the feed\n",
        "    cap = cv2.VideoCapture(input_loc)\n",
        "    # Find the number of frames\n",
        "    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1\n",
        "    print (\"Number of frames: \", video_length)\n",
        "    count = 0\n",
        "    print (\"Converting video..\\n\")\n",
        "    # Start converting the video\n",
        "    while cap.isOpened():\n",
        "        # Extract the frame\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            continue\n",
        "        # Write the results back to output location.\n",
        "        cv2.imwrite(output_loc + \"/%#05d.jpg\" % (count+1), frame)\n",
        "        count = count + 1\n",
        "        # If there are no more frames left\n",
        "        if (count > (video_length-1)):\n",
        "            # Log the time again\n",
        "            time_end = time.time()\n",
        "            # Release the feed\n",
        "            cap.release()\n",
        "            # Print stats\n",
        "            print (\"Done extracting frames.\\n%d frames extracted\" % count)\n",
        "            print (\"It took %d seconds forconversion.\" % (time_end-time_start))\n",
        "            break"
      ],
      "metadata": {
        "id": "p2Vz9-HzSRtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'abnormal'\n",
        "output_dir = filename + '-output/'\n",
        "os.mkdir(filename + '-frames/')\n",
        "os.mkdir(output_dir)\n",
        "\n",
        "input_loc = filename + '.mp4'\n",
        "output_loc = filename + '-frames/'\n",
        "video_to_frames(input_loc, output_loc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CCpBTHOHibV",
        "outputId": "1c2dbb60-3956-4645-c3db-cbe8322a1e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of frames:  -1\n",
            "Converting video..\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video = cv2.VideoCapture(input_loc);\n",
        "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "if int(major_ver)  < 3 :\n",
        "        fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "        print (\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
        "else :\n",
        "        fps = video.get(cv2.CAP_PROP_FPS)\n",
        "        print (\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "video.release()\n"
      ],
      "metadata": {
        "id": "xiz9KxtsrSp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "945a151a-d24c-43e5-ecd8-56acbe043283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames per second using video.get(cv2.CAP_PROP_FPS) : 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rotate images as needed\n",
        "rotated_dir = filename + '-rotated2/'\n",
        "os.mkdir(rotated_dir)\n",
        "\n",
        "for name in sorted(os.listdir(output_loc)):\n",
        "  image = cv2.rotate(cv2.imread(output_loc + '/' + name), cv2.cv2.ROTATE_90_CLOCKWISE)\n",
        "  cv2.imwrite(rotated_dir + name, image ) \n"
      ],
      "metadata": {
        "id": "DK76lO_hvsM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find nose reference point"
      ],
      "metadata": {
        "id": "djyiRDh5ap3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Read images with OpenCV.\n",
        "#images = {name: cv2.resize(cv2.imread(rotated_dir + name),(512,512)) for name in sorted(os.listdir(rotated_dir))}\n",
        "\n",
        "# Preview the images.\n",
        "#for name, image in images.items():\n",
        "  #print(name)   \n",
        "  #cv2_imshow(image)"
      ],
      "metadata": {
        "id": "e2E-Dj8PYwXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Read images with OpenCV.\n",
        "#images = {name: cv2.imread(\"frames2/\" + name) for name in sorted(os.listdir(\"frames2/\"))}\n",
        "images = {name: cv2.imread(rotated_dir + name) for name in sorted(os.listdir(rotated_dir))}\n",
        "\n",
        "# Preview the images.\n",
        "#for name, image in images.items():\n",
        "  #print(name)   \n",
        "  #cv2_imshow(image)"
      ],
      "metadata": {
        "id": "Ksb6Bojlr0A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbKTRBS2srNu",
        "outputId": "9bfa1c89-121c-4f13-ae7c-68a9c2d9938a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(rotated_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8_d6NxlPCpy",
        "outputId": "f43009cf-905e-465a-d162-89b813f02583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['base.jpg', '9.jpg', '6.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r abnormal-rotated2/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "yuLjC2ShPL-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import imutils\n",
        "mp_face_mesh = mp.solutions.face_mesh"
      ],
      "metadata": {
        "id": "wC9sheNkZA1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare DrawingSpec for drawing the face landmarks later.\n",
        "mp_drawing = mp.solutions.drawing_utils \n",
        "drawing_spec = mp_drawing.DrawingSpec(thickness=2, circle_radius=3)"
      ],
      "metadata": {
        "id": "kJr-vKyKZChs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_filename2 = filename + \"-results.csv\"\n",
        "with open(text_filename2, 'a') as f:\n",
        "          f.write('R-X' + ',' + 'R-Y' + ',' + 'R-R' + ',' +\n",
        "                  'L-X' + ',' + 'L-Y' + ',' + 'L-R' + ',' +\n",
        "                  'N-X' + ',' + 'N-Y' + ',' + 'dot' + '\\n')\n",
        "          \n",
        "                  "
      ],
      "metadata": {
        "id": "tphve9O7bHqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_limbus(image, prefix, point ,side):\n",
        "    #cv2.imwrite(output_dir + '/' + 'before-' + prefix + name , image ) \n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (15,15), 0)\n",
        "    edged = cv2.Canny(gray, 50, 75)\n",
        "    edged = cv2.dilate(edged, None, iterations=1)\n",
        "    edged = cv2.erode(edged, None, iterations=1)\n",
        "    cv2.imwrite(output_dir + '/' + prefix + name , edged ) \n",
        "    \n",
        "    \n",
        "    cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "      cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    \n",
        "    # TO DO !!!  Take the leftmost / rightmost cntour (based on the image)\n",
        "    # side = 0 -> left\n",
        "    # side = 1 -> right\n",
        "    # side = 2 -> top\n",
        "\n",
        "\n",
        "    rectangles = []\n",
        "    for c in cnts:\n",
        "      x,y,w,h = cv2.boundingRect(c)\n",
        "      if (w*h > 250): # remove all small rectangles\n",
        "        rectangles.append([x,y,w,h])\n",
        "        cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,255) , 1)\n",
        "      else:\n",
        "        cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,255) , -1)\n",
        "      #cv2.putText(image, str(x), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1,  (0, 255, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    cv2.imwrite(output_dir + '/' + 'before1-' + prefix + name , image ) \n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    by_x = sorted(rectangles, key=lambda x: x[0])  # x values\n",
        "    #for x, y, w, h in contours:\n",
        "    #print(f\"{x:4} {y:4} {w:4} {h:4}\") \n",
        "    if (len(rectangles) > 0):\n",
        "      if (side==0):\n",
        "       max_x, max_y, max_w, max_h = by_x[-1]\n",
        "      elif (side==1):\n",
        "       max_x, max_y, max_w, max_h = by_x[0]\n",
        "    else:\n",
        "      max_x, max_y, max_w, max_h = 0,0,0,0\n",
        "\n",
        "    \n",
        "    by_y = sorted(rectangles, key=lambda x: x[1] + x[3])  # x values\n",
        "    if (len(rectangles) > 0):\n",
        "      if (side==2):\n",
        "       max_x, max_y, max_w, max_h = by_y[0]\n",
        "      elif (side==3) :\n",
        "       max_x, max_y, max_w, max_h = by_y[-1]\n",
        "   \n",
        "    cv2.rectangle(image, (max_x,max_y), (max_x+max_w, max_y+max_h), (255,0,0) , 1)\n",
        "    return max_x, max_y, max_w, max_h\n",
        "\n",
        "'''\n",
        "    # take the biggest rectangle\n",
        "    max_size = 0\n",
        "    location = 0\n",
        "    max_len = 0\n",
        "    max_x, max_w, max_y, max_h = 0, 0, 0, 0\n",
        "    print(prefix, ' has ', len(cnts), ' cnts')\n",
        "    for c in cnts:\n",
        "      x,y,w,h = cv2.boundingRect(c)\n",
        "      #epsilon = 0.1*cv2.arcLength(c,False)\n",
        "      #approx = cv2.approxPolyDP(c,epsilon,False)\n",
        "      #cv2.drawContours(image, [approx], -1, (0, 0, 255), 3)\n",
        "      print('len=', cv2.arcLength(c,False))\n",
        "      current_len = cv2.arcLength(c,False)\n",
        "      if (current_len > max_len):\n",
        "        max_len = current_len\n",
        "        location = c\n",
        "      #cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,255) , 1)\n",
        "      #if (w*h > max_size):\n",
        "      #  max_size = w*h\n",
        "      #  max_x, max_y, max_w, max_h = x, y, w, h\n",
        "\n",
        "    if (max_len > 0):\n",
        "      print(\"Draw Hull\")\n",
        "      #cv2.drawContours(image, [location], -1, (0, 0, 255), 2)\n",
        "      hull = cv2.convexHull(c, False)\n",
        "      cv2.drawContours(image, hull, -1, (0, 0, 255), 1)\n",
        "      cv2.imwrite(output_dir + '/' + 'before1-' + prefix + name , image ) \n",
        "\n",
        "\n",
        "      max_x, max_y, max_w, max_h = cv2.boundingRect(location)\n",
        "\n",
        "    #IF THE DETECTED EDGE IS THE EDGE OF THE IMAGE THEN IGNORE RECOMMENDATION\n",
        "    #if (max_x + max_w == image.shape[0]):\n",
        "    #  print(\"Max reached\")\n",
        "    #  x,y = point\n",
        "    #else:\n",
        "    #  x,y = max_x, max_y\n",
        "\n",
        "\n",
        "    # CAN WE USE THE DIRECTION OF THE COUNTOUER ???\n",
        "\n",
        "    #print(\"found \", max_x, max_y, max_w, max_h, image.shape[0], image.shape[1])\n",
        "    #cv2.rectangle(image, (max_x,max_y), (max_x+max_w, max_y+max_h), (0,255,255) , 1)\n",
        "    #cv2.imwrite(output_dir + '/' + 'before-' + prefix + name , image ) \n",
        "    #cv2.rectangle(edged, (max_x,max_y), (max_x+max_w, max_y+max_h), (0,255,255) , 1)\n",
        "\n",
        "    print(max_x, max_w, image.shape[0], image.shape[1])\n",
        "    ## SAME FOR MIN SIDE  \n",
        "\n",
        "    return max_x, max_y, max_w  \n",
        "'''"
      ],
      "metadata": {
        "id": "ZL3ZSZM4eafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "6a8c83bf-76db-4945-c60f-db7dee926b2b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    # take the biggest rectangle\\n    max_size = 0\\n    location = 0\\n    max_len = 0\\n    max_x, max_w, max_y, max_h = 0, 0, 0, 0\\n    print(prefix, \\' has \\', len(cnts), \\' cnts\\')\\n    for c in cnts:\\n      x,y,w,h = cv2.boundingRect(c)\\n      #epsilon = 0.1*cv2.arcLength(c,False)\\n      #approx = cv2.approxPolyDP(c,epsilon,False)\\n      #cv2.drawContours(image, [approx], -1, (0, 0, 255), 3)\\n      print(\\'len=\\', cv2.arcLength(c,False))\\n      current_len = cv2.arcLength(c,False)\\n      if (current_len > max_len):\\n        max_len = current_len\\n        location = c\\n      #cv2.rectangle(image, (x,y), (x+w, y+h), (0,255,255) , 1)\\n      #if (w*h > max_size):\\n      #  max_size = w*h\\n      #  max_x, max_y, max_w, max_h = x, y, w, h\\n\\n    if (max_len > 0):\\n      print(\"Draw Hull\")\\n      #cv2.drawContours(image, [location], -1, (0, 0, 255), 2)\\n      hull = cv2.convexHull(c, False)\\n      cv2.drawContours(image, hull, -1, (0, 0, 255), 1)\\n      cv2.imwrite(output_dir + \\'/\\' + \\'before1-\\' + prefix + name , image ) \\n\\n\\n      max_x, max_y, max_w, max_h = cv2.boundingRect(location)\\n\\n    #IF THE DETECTED EDGE IS THE EDGE OF THE IMAGE THEN IGNORE RECOMMENDATION\\n    #if (max_x + max_w == image.shape[0]):\\n    #  print(\"Max reached\")\\n    #  x,y = point\\n    #else:\\n    #  x,y = max_x, max_y\\n\\n\\n    # CAN WE USE THE DIRECTION OF THE COUNTOUER ???\\n\\n    #print(\"found \", max_x, max_y, max_w, max_h, image.shape[0], image.shape[1])\\n    #cv2.rectangle(image, (max_x,max_y), (max_x+max_w, max_y+max_h), (0,255,255) , 1)\\n    #cv2.imwrite(output_dir + \\'/\\' + \\'before-\\' + prefix + name , image ) \\n    #cv2.rectangle(edged, (max_x,max_y), (max_x+max_w, max_y+max_h), (0,255,255) , 1)\\n\\n    print(max_x, max_w, image.shape[0], image.shape[1])\\n    ## SAME FOR MIN SIDE  \\n\\n    return max_x, max_y, max_w  \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with mp_face_mesh.FaceMesh( max_num_faces=1, refine_landmarks=True,\n",
        "    static_image_mode=True,\n",
        "    min_detection_confidence=0.45) as face_mesh:\n",
        "  for name, image in images.items():\n",
        "    # Convert the BGR image to RGB and process it with MediaPipe Face Mesh.\n",
        "    #image = cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    print(f'Face landmarks of {name}:')\n",
        "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    # Draw face landmarks of each face.\n",
        "   \n",
        "    if not results.multi_face_landmarks:\n",
        "      continue\n",
        "    print(name)\n",
        "\n",
        "    annotated_image = image.copy()\n",
        "    for face_landmarks in results.multi_face_landmarks:\n",
        "       print(\"found eyes\")\n",
        "       height, width, _ = annotated_image.shape\n",
        "       nose = [int(face_landmarks.landmark[168].x * width), int(face_landmarks.landmark[168].y * height)]\n",
        "       #cv2.circle(annotated_image, (nose[0], nose[1]), 3, (0, 0, 255), -1)\n",
        "  \n",
        "\n",
        "       leftIrisPoints = [474, 475, 476, 477]\n",
        "       rightIrisPoints = [469, 470, 471, 472]\n",
        "       #right, top, left, bottom\n",
        "    \n",
        "       left_iris = []\n",
        "       for p in leftIrisPoints:\n",
        "             point = [int(face_landmarks.landmark[p].x * width), int(face_landmarks.landmark[p].y * height)]\n",
        "             left_iris.append(point)\n",
        "\n",
        "       right_iris = []\n",
        "       for p in rightIrisPoints:\n",
        "               point = [int(face_landmarks.landmark[p].x * width), int(face_landmarks.landmark[p].y * height)]\n",
        "               right_iris.append(point)\n",
        "\n",
        "    leftIris_leftside  = (int( left_iris[2][0]), int( left_iris[2][1]))\n",
        "    leftIris_righside  = (int( left_iris[0][0]), int( left_iris[0][1]))\n",
        "    leftIris_top       = (int( left_iris[1][0]), int( left_iris[1][1]))\n",
        "    leftIris_bottom    = (int( left_iris[3][0]), int( left_iris[3][1]))\n",
        "    rightIris_leftside = (int(right_iris[2][0]), int(right_iris[2][1]))\n",
        "    rightIris_righside = (int(right_iris[0][0]), int(right_iris[0][1]))\n",
        "    rightIris_top      = (int(right_iris[1][0]), int(right_iris[1][1]))\n",
        "    rightIris_bottom   = (int(right_iris[3][0]), int(right_iris[3][1]))\n",
        "\n",
        "\n",
        "\n",
        "    # REDUCE HIGHT A BIT TO PREVENT EYELID\n",
        "    height_margin = 20\n",
        "\n",
        "    margin = 25\n",
        "    '''\n",
        "    # Left Iris Left Limbus \n",
        "    leftIris_leftLimbus_image = annotated_image[int(left_iris[1][1])  + height_margin :int(left_iris[3][1]) - height_margin, \n",
        "                                                int(left_iris[2][0]) - margin :int(left_iris[2][0]) + margin, \n",
        "                                               :]\n",
        "    x, y, w = find_limbus(leftIris_leftLimbus_image, 'leftIris_leftLimbus=', leftIris_leftside, 0)\n",
        "    cv2.rectangle(annotated_image, \n",
        "                    (x - margin + int(left_iris[2][0]) , height_margin + int(left_iris[1][1])) ,\n",
        "                    (x - margin + int(left_iris[2][0]) , height_margin + int(left_iris[3][1])) , \n",
        "                    (0,255,0) , 2)\n",
        "    #cv2.imwrite(output_dir + '/' + 'leftIris-leftLimbus-' + name , leftIris_leftLimbus_image )      \n",
        "\n",
        "    # Left Iris Right Limbus \n",
        "    leftIris_rightLimbus_image = annotated_image[int(left_iris[1][1]) + height_margin :int(left_iris[3][1]) - height_margin, \n",
        "                                                int(left_iris[0][0]) - margin :int(left_iris[0][0]) + margin, \n",
        "                                               :]\n",
        "    x, y, w = find_limbus(leftIris_rightLimbus_image, 'leftIris_rightLimbus=', leftIris_righside, 1)\n",
        "    cv2.rectangle(annotated_image, \n",
        "                    (x - margin + w + int(left_iris[0][0]) , height_margin + int(left_iris[1][1])) ,\n",
        "                    (x - margin + w + int(left_iris[0][0]) , height_margin + int(left_iris[3][1])) , \n",
        "                    (0,255,0) , 2)\n",
        "    #cv2.imwrite(output_dir + '/' + 'leftIris-rightLimbus-' + name , leftIris_rightLimbus_image )   \n",
        "\n",
        "    # Right Iris Left Limbus\n",
        "    rightIris_leftLimbus_image = annotated_image[int(right_iris[1][1]) + height_margin :int(right_iris[3][1]) - height_margin, \n",
        "                                                int(right_iris[2][0]) - margin :int(right_iris[2][0]) + margin, \n",
        "                                               :]\n",
        "    x, y, w = find_limbus(rightIris_leftLimbus_image, 'rightIris_leftLimbus=', rightIris_leftside, 0)\n",
        "    cv2.rectangle(annotated_image, \n",
        "                    (x - margin + int(right_iris[2][0]) , height_margin + int(right_iris[1][1])) ,\n",
        "                    (x - margin + int(right_iris[2][0]) , height_margin + int(right_iris[3][1])) , \n",
        "                    (0,255,0) , 2)\n",
        "    #cv2.imwrite(output_dir + '/' + 'rightIris-leftLimbus-' + name , rightIris_leftLimbus_image )      \n",
        "\n",
        "    # Right Iris Right Limbus\n",
        "    rightIris_rightLimbus_image = annotated_image[int(right_iris[1][1]) + height_margin :int(right_iris[3][1]) - height_margin, \n",
        "                                                 int(right_iris[0][0]) - margin :int(right_iris[0][0]) + margin, \n",
        "                                               :]\n",
        "    x, y, w = find_limbus(rightIris_rightLimbus_image, 'rightIris_rightLimbus=', rightIris_righside, 1)\n",
        "    cv2.rectangle(annotated_image, \n",
        "                    (x - margin + w + int(right_iris[0][0]) , height_margin + int(right_iris[1][1])) ,\n",
        "                    (x - margin + w + int(right_iris[0][0]) , height_margin + int(right_iris[3][1])) , \n",
        "                    (0,255,0) , 2)\n",
        "    #cv2.imwrite(output_dir + '/' + 'rightIris-rightLimbus-' + name , rightIris_rightLimbus_image )      \n",
        "'''   \n",
        "    leftIrisCenter = (int((left_iris[0][0] + left_iris[2][0])/2), int((left_iris[1][1] + left_iris[3][1])/2))\n",
        "    leftIrisRadius =  int(abs(left_iris[0][0] - left_iris[2][0])/2)\n",
        "    rightIrisCenter = (int((right_iris[0][0] + right_iris[2][0])/2), int((right_iris[1][1] + right_iris[3][1])/2))\n",
        "    rightIrisRadius = int(abs(right_iris[0][0] - right_iris[2][0])/2)\n",
        "\n",
        "    #cv2.circle(annotated_image, leftIrisCenter, leftIrisRadius, (0, 255, 0), 1)\n",
        "    #cv2.circle(annotated_image, rightIrisCenter, rightIrisRadius, (0, 255, 0), 1)\n",
        "    #cv2.circle(annotated_image, leftIrisCenter, 5, (0, 255, 0), 3)\n",
        "    #cv2.circle(annotated_image, rightIrisCenter, 5, (0, 255, 0), 3)\n",
        "\n",
        "    #cv2.circle(annotated_image, leftIris_leftside, 2, (0, 255, 0), 3) # patient left\n",
        "    #cv2.putText(annotated_image, 'LL', leftIris_leftside, cv2.FONT_HERSHEY_SIMPLEX, 1,  (0, 255, 0), 2, cv2.LINE_AA)\n",
        "    \n",
        "    #cv2.circle(annotated_image, leftIris_righside, 2, (0, 255, 0), 3)\n",
        "    #cv2.putText(annotated_image, 'LR', leftIris_righside, cv2.FONT_HERSHEY_SIMPLEX, 1,  (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    \n",
        "    cv2.circle(annotated_image, leftIris_top, 2, (0, 255, 0), 3) # patient left\n",
        "    cv2.putText(annotated_image, 'LT', leftIris_top, cv2.FONT_HERSHEY_SIMPLEX, 1,  (0, 255, 0), 2, cv2.LINE_AA)\n",
        "    \n",
        "    cv2.circle(annotated_image, leftIris_bottom, 2, (0, 255, 0), 3)\n",
        "    #cv2.putText(annotated_image, 'LB', leftIris_bottom, cv2.FONT_HERSHEY_SIMPLEX, 1,  (0, 255, 0), 2, cv2.LINE_AA)\n",
        "    \n",
        "\n",
        "\n",
        "    #cv2.circle(annotated_image, rightIris_leftside, 2, (0, 255, 0), 3) # patient left\n",
        "    #cv2.putText(annotated_image, 'RL', rightIris_leftside, cv2.FONT_HERSHEY_SIMPLEX, 1,  (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    #cv2.circle(annotated_image, rightIris_righside, 2, (0, 255, 0), 3)\n",
        "    cv2.putText(annotated_image, 'RR', rightIris_righside, cv2.FONT_HERSHEY_SIMPLEX, 1,  (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    \n",
        "    cv2.circle(annotated_image, rightIris_top, 2, (0, 255, 0), 3) # patient left\n",
        "    cv2.putText(annotated_image, 'RT', rightIris_top, cv2.FONT_HERSHEY_SIMPLEX, 1,  (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    cv2.circle(annotated_image, rightIris_bottom, 2, (0, 255, 0), 3)\n",
        "    #cv2.putText(annotated_image, 'RB', rightIris_bottom, cv2.FONT_HERSHEY_SIMPLEX, 1,  (0, 255, 0), 2, cv2.LINE_AA)\n",
        "    \n",
        "    # Top and bottom\n",
        "\n",
        "    y_margin = 50\n",
        "    # Left Iris Top Limbus \n",
        "    leftIris_topLimbus_image = annotated_image[int(left_iris[1][1]) : int(left_iris[1][1]) + y_margin, \n",
        "                                               int(left_iris[2][0]) : int(left_iris[0][0]), \n",
        "                                               :]\n",
        "    x, y, w, h = find_limbus(leftIris_topLimbus_image, 'leftIris_topLimbus=', leftIris_top, 2)\n",
        "    cv2.rectangle(annotated_image, \n",
        "                 (int(left_iris[2][0]) , int(left_iris[1][1]) + y) ,\n",
        "                 (int(left_iris[0][0]) , int(left_iris[1][1]) + y) , \n",
        "                 (0,255,0) , 2)\n",
        "    \n",
        "\n",
        "    # top limbus area\n",
        "    #cv2.rectangle(annotated_image, \n",
        "    #                (int(left_iris[2][0]) , int(left_iris[1][1])) ,\n",
        "    #                (int(left_iris[0][0]) , int(left_iris[1][1]) + y_margin) , \n",
        "    #                (0,255,0) , 2)\n",
        "    \n",
        "    # left Iris bottom Limbus\n",
        "    leftIris_bottomLimbus_image = annotated_image[int(left_iris[3][1]) - y_margin : int(left_iris[3][1]), \n",
        "                                                  int(left_iris[2][0]) : int(left_iris[0][0]), \n",
        "                                                  :]\n",
        "    x, y, w, h = find_limbus(leftIris_bottomLimbus_image, 'leftIris_bottomLimbus=', leftIris_bottom, 3)\n",
        "    cv2.rectangle(annotated_image, \n",
        "                  (int(left_iris[2][0]) , int(left_iris[3][1]) - y_margin + y + h) ,\n",
        "                  (int(left_iris[0][0]) , int(left_iris[3][1]) - y_margin + y + h) , \n",
        "                  (0,255,0) , 2)\n",
        "   \n",
        "    #cv2.rectangle(annotated_image, \n",
        "    #                (int(left_iris[2][0]) , int(left_iris[3][1]) - y_margin) ,\n",
        "    #                (int(left_iris[0][0]) , int(left_iris[3][1])) , \n",
        "    #                (0,255,0) , 2)\n",
        "   \n",
        "    # Right iris top Limbus\n",
        "    rightIris_topLimbus_image = annotated_image[int(right_iris[1][1]) : int(right_iris[1][1]) + y_margin, \n",
        "                                               int(right_iris[2][0]) : int(right_iris[0][0]), \n",
        "                                               :]\n",
        "    x, y, w, h = find_limbus(rightIris_topLimbus_image, 'rightIris_topLimbus=', rightIris_top, 2)\n",
        "    cv2.rectangle(annotated_image, \n",
        "                 (int(right_iris[2][0]) , int(right_iris[1][1]) + y) ,\n",
        "                 (int(right_iris[0][0]) , int(right_iris[1][1]) + y) , \n",
        "                 (0,255,0) , 2)\n",
        "    \n",
        "    # Whole area\n",
        "    # cv2.rectangle(annotated_image, \n",
        "    #                (int(right_iris[2][0]) , int(right_iris[1][1])) ,\n",
        "    #                (int(right_iris[0][0]) , int(right_iris[1][1]) + y_margin) , \n",
        "    #                (0,255,0) , 2)\n",
        "\n",
        "    # Right iris bottom Limbus\n",
        "    rightIris_bottomLimbus_image = annotated_image[int(right_iris[3][1]) - y_margin : int(right_iris[3][1]), \n",
        "                                                  int(right_iris[2][0]) : int(right_iris[0][0]), \n",
        "                                                  :]\n",
        "    x, y, w, h = find_limbus(rightIris_bottomLimbus_image, 'rightIris_bottomLimbus=', rightIris_bottom, 3)\n",
        "    cv2.rectangle(annotated_image, \n",
        "                  (int(right_iris[2][0]) , int(right_iris[3][1]) - y_margin + y + h) ,\n",
        "                  (int(right_iris[0][0]) , int(right_iris[3][1]) - y_margin + y + h) , \n",
        "                  (0,255,0) , 2)\n",
        "   \n",
        "    \n",
        "    # whole area\n",
        "    # cv2.rectangle(annotated_image, \n",
        "    #                (int(right_iris[2][0]) , int(right_iris[3][1]) - y_margin) ,\n",
        "    #                (int(right_iris[0][0]) , int(right_iris[3][1])) , \n",
        "    #                (0,255,0) , 2)\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Find the sticker\n",
        "    x_adjustment = 50\n",
        "    x1 = (int(face_landmarks.landmark[109].x * width), int(face_landmarks.landmark[109].y * height) - x_adjustment)\n",
        "    x4 = (int(face_landmarks.landmark[336].x * width), int(face_landmarks.landmark[336].y * height))\n",
        "    #cv2.rectangle(annotated_image, x1,  x4, (0,255,255), 2) # yellow\n",
        "    # print(\"point=\", x1, x4)\n",
        "    # NEEDS TO BE HIGHER!\n",
        "\n",
        "    #cv2.rectangle(annotated_image, x1, x4, (0, 0, 255), 2)# red\n",
        "    annotated_image_copy = annotated_image[x1[1]:x4[1], x1[0]:x4[0], :]\n",
        "    #cv2.imwrite(output_dir + '/' + 'copy-' + name , annotated_image_copy )   \n",
        "\n",
        "\n",
        "    gray = cv2.cvtColor(annotated_image_copy, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (11,11), 0)\n",
        "    edged = cv2.Canny(gray, 10, 100)\n",
        "    edged = cv2.dilate(edged, None, iterations=1)\n",
        "    edged = cv2.erode(edged, None, iterations=1)\n",
        "    #cv2.imwrite(output_dir + '/' + 'edged-' + name , edged )   \n",
        "\n",
        "    circle_size = 0\n",
        "    center = (0,0)\n",
        "    # find contours in the edge map\n",
        "    cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "      cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    for c in cnts:\n",
        "\t      # if the contour is not sufficiently large, ignore it\n",
        "        if cv2.contourArea(c) < 75:\n",
        "\t\t        continue\n",
        "        print(\"found dot\")\n",
        "\t      # compute the rotated bounding box of the contour\n",
        "        orig = annotated_image_copy.copy()\n",
        "        box = cv2.minAreaRect(c)  # (center, (hgight, weight), angle)\n",
        "        box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n",
        "        box = np.array(box, dtype=\"int\")\n",
        "\n",
        "        center, radius = cv2.minEnclosingCircle(c)\n",
        "\n",
        "        circle_size = 2 * radius \n",
        "        if (circle_size < 180):\n",
        "            #print(\"circle_size < 180\")\n",
        "            continue\n",
        "        print(\"circle_size=\", circle_size)    \n",
        "        cv2.putText(annotated_image_copy, str(round(2*radius)), \n",
        "                 (int(center[0]), int(center[1])), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                 1,  (0, 255, 0), 2, cv2.LINE_AA)    \n",
        "        cv2.circle(annotated_image_copy, (int(center[0]), int(center[1])), 5, (0,0,255), 3)\n",
        "        cv2.circle(annotated_image_copy, (int(center[0]), int(center[1])), int(radius), (0,0,255), 2)\n",
        "        #cv2.imwrite(output_dir + '/' + 'sticker-' + name , annotated_image_copy )  \n",
        "        \n",
        "        actual_center=[0,0]\n",
        "        actual_center[0] = center[0] + x1[0]\n",
        "        actual_center[1] = center[1] + x1[1]\n",
        "        cv2.putText(annotated_image, str(round(2*radius)), \n",
        "                 (int(actual_center[0]), int(actual_center[1])), cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                 1,  (0, 255, 0), 2, cv2.LINE_AA)    \n",
        "        cv2.circle(annotated_image, (int(actual_center[0]), int(actual_center[1])), 5, (0,0,255), 3)\n",
        "        cv2.circle(annotated_image, (int(actual_center[0]), int(actual_center[1])), int(radius), (0,0,255), 2)\n",
        " \n",
        "       \n",
        "  \n",
        "    print(str(leftIrisCenter[0])  + ',' + str(leftIrisCenter[1])  + ',' + str(leftIrisRadius) + ',' + \n",
        "                  str(rightIrisCenter[0]) + ',' + str(rightIrisCenter[1]) + ',' + str(rightIrisRadius) + ',' + \n",
        "                  str(nose[0]) + ',' + str(nose[1]) + ',' + str(circle_size))\n",
        "    with open(text_filename2, 'a') as f:\n",
        "          f.write(name + ',' + \n",
        "                  str(x - margin + int(left_iris[2][0])) + ',' +\n",
        "                  str(x - margin + w + int(left_iris[0][0])) + ',' +\n",
        "                  str(x - margin + int(right_iris[2][0])) + ',' +\n",
        "                  str(x - margin + w + int(right_iris[0][0])) + ',' +\n",
        "                  str(int(actual_center[0])) + ',' + str(int(actual_center[1])) + ',' +\n",
        "                  str(circle_size) + '\\n')\n",
        "          '''\n",
        "                  str(leftIris_leftside[0])  + ',' + str(leftIris_leftside[1])  + ',' + \n",
        "                  str(leftIris_righside[0])  + ',' + str(leftIris_righside[1])  + ',' + \n",
        "                  str(rightIris_leftside[0])  + ',' + str(rightIris_leftside[1])  + ',' + \n",
        "                  str(rightIris_righside[0])  + ',' + str(rightIris_righside[1])  + ',' + \n",
        "                  \n",
        "          '''\n",
        "                  #str(nose[0]) + ',' + str(nose[1]) + ',' + \n",
        "                \n",
        "    print(\"writing file:\",output_dir + '/' + name)\n",
        "    cv2.imwrite(output_dir + '/' + name, annotated_image )   \n",
        "       \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3jE8tCxZC6h",
        "outputId": "00282d59-e98e-4fbf-9b38-188d4c7e9ca5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Face landmarks of 12.jpg:\n",
            "12.jpg\n",
            "found eyes\n",
            "found dot\n",
            "circle_size= 189.66909790039062\n",
            "found dot\n",
            "found dot\n",
            "circle_size= 185.2837677001953\n",
            "1237,2080,57,656,2062,57,961,2061,185.2837677001953\n",
            "writing file: abnormal-output//12.jpg\n",
            "Face landmarks of 6.jpg:\n",
            "6.jpg\n",
            "found eyes\n",
            "found dot\n",
            "circle_size= 203.7537384033203\n",
            "1257,2015,54,651,1986,56,952,1932,203.7537384033203\n",
            "writing file: abnormal-output//6.jpg\n",
            "Face landmarks of base.jpg:\n",
            "base.jpg\n",
            "found eyes\n",
            "found dot\n",
            "circle_size= 189.21435546875\n",
            "1207,2130,55,614,2120,56,917,2089,189.21435546875\n",
            "writing file: abnormal-output//base.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/zivp100/EyeCareX.git"
      ],
      "metadata": {
        "id": "uPwCB9CPcFHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imutils\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7QGOIqGWTvh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TmH21eXrhlW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#put all the results in on dataframe\n",
        "df1 = pd.read_csv('results2.csv')\n",
        "df2 = pd.read_csv('results.csv')\n",
        "df  = pd.merge(df1, df2, on='filename')\n",
        "\n",
        "df['Left_center_X'] = (df['L-TL-X'] + df['L-BP-X'])/2\n",
        "df['Left_center_Y'] = (df['L-TL-Y'] + df['L-BP-Y'])/2\n",
        "\n",
        "df['Left_X_from_nose'] =  abs(df['Nose-X'] + df['Left_center_X'])\n",
        "df['Left_Y_from_nose'] =  abs(df['Nose-Y'] + df['Left_center_Y'])\n",
        "\n",
        "df['X_change'] = df['Left_X_from_nose'] - df['Left_X_from_nose'].shift(1)\n",
        "df['Y_change'] = df['Left_Y_from_nose'] - df['Left_Y_from_nose'].shift(1)"
      ],
      "metadata": {
        "id": "rM2mqrFwhlaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#put all the results in on dataframe\n",
        "df = pd.read_csv('results-a.csv')\n",
        "#df2 = pd.read_csv('results.csv')\n",
        "#df  = pd.merge(df1, df2, on='filename')\n",
        "\n",
        "df['Left_center_X'] = (df['L-TL-X'] + df['L-BP-X'])/2\n",
        "df['Left_center_Y'] = (df['L-TL-Y'] + df['L-BP-Y'])/2\n",
        "\n",
        "df['Left_X_from_nose'] =  abs( df['Left_center_X']) #df['Nose-X']) +\n",
        "df['Left_Y_from_nose'] =  abs( df['Left_center_Y']) #df['Nose-Y']) +\n",
        "\n",
        "df['X_change'] = df['Left_X_from_nose'] - df['Left_X_from_nose'].shift(1)\n",
        "df['Y_change'] = df['Left_Y_from_nose'] - df['Left_Y_from_nose'].shift(1)"
      ],
      "metadata": {
        "id": "7TZ4XrI_zdEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df['X_change'])\n",
        "plt.show"
      ],
      "metadata": {
        "id": "UrOehoeEkVOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=[]\n",
        "\n",
        "for filename in sorted(os.listdir(\"frames2/\")):\n",
        "    if filename.endswith(\".jpg\"): \n",
        "          print(filename)\n",
        "          my_img = cv2.imread(\"frames2/\" + filename)\n",
        "          img.append(my_img)\n",
        "\n",
        "height,width,layers=img[1].shape\n",
        "\n",
        "video = cv2.VideoWriter(\"output.avi\",cv2.VideoWriter_fourcc(*\"MJPG\"), fps,(width,height))\n",
        "\n",
        "for j in range(len(img)):\n",
        "    video.write(img[j])\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "metadata": {
        "id": "EfU7quwxYxBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/file2.zip /content/abnormal-output/"
      ],
      "metadata": {
        "id": "HfCpCcWciQHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  '''\n",
        "    with open(text_filename2, 'a') as f:\n",
        "          f.write(name + ',' + \n",
        "                  str(right_iris[0][0]) + ',' + str(right_iris[0][1]) + ',' +  str(leftIrisRadius) + ',' + \n",
        "                  str(right_iris[1][1]) + ',' +\n",
        "                  str(right_iris[2][0]) + ',' + str(right_iris[2][1]) + ',' +\n",
        "                  str(right_iris[3][0]) + ',' + str(right_iris[3][1]) + ',' +                                                                                                                   \n",
        "                  str(left_iris[0][0])  + ',' + str(left_iris[0][1]) + ',' +\n",
        "                  str(left_iris[1][0])  + ',' + str(left_iris[1][1]) + ',' +\n",
        "                  str(left_iris[2][0])  + ',' + str(left_iris[2][1]) + ',' +\n",
        "                  str(left_iris[3][0])  + ',' + str(left_iris[3][1]) + ',' +\n",
        "                  str(nose[0]) + ',' + str(nose[1]) + '\\n')\n",
        "\n",
        "    for index in range(len(right_iris) - 1):\n",
        "           print(right_iris[index])\n",
        "           cv2.line(annotated_image, tuple(right_iris[index]), \n",
        "                    tuple(right_iris[index + 1]), (0, 255, 0), 1)\n",
        "           cv2.circle(annotated_image, tuple(right_iris[index]), 2, (0, 255, 0), -1)\n",
        "    cv2.circle(annotated_image, tuple(right_iris[len(right_iris) - 1]), 2, (0, 255, 0), -1)\n",
        "    cv2.line(annotated_image, tuple(right_iris[len(right_iris) - 1]), tuple(right_iris[0]), (0, 255, 0), 1)\n",
        "\n",
        "    for index in range(len(left_iris) - 1):\n",
        "           cv2.line(annotated_image, tuple(left_iris[index]), \n",
        "                    tuple(left_iris[index + 1]), (0, 255, 0), 1)\n",
        "           cv2.circle(annotated_image, tuple(left_iris[index]), 2, (0, 255, 0), -1)\n",
        "    cv2.circle(annotated_image, tuple(left_iris[len(left_iris) - 1]), 2, (0, 255, 0), -1)\n",
        "    cv2.line(annotated_image, tuple(left_iris[len(left_iris) - 1]), tuple(left_iris[0]), (0, 255, 0), 1)\n",
        "    '''"
      ],
      "metadata": {
        "id": "OAXEvrc8ulUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = 'output2/'\n"
      ],
      "metadata": {
        "id": "FhD88Vedhmjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance as dist\n",
        "from imutils import perspective\n",
        "from imutils import contours\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2"
      ],
      "metadata": {
        "id": "z1LlmQNTm0lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with mp_face_mesh.FaceMesh( max_num_faces=1, refine_landmarks=True,\n",
        "    static_image_mode=True,\n",
        "    min_detection_confidence=0.45) as face_mesh:\n",
        "  for name, image in images.items():\n",
        "    # Convert the BGR image to RGB and process it with MediaPipe Face Mesh.\n",
        "    #image = cv2.rotate(image, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    # Draw face landmarks of each face.\n",
        "    print(f'Face landmarks of {name}:')\n",
        "    if not results.multi_face_landmarks:\n",
        "      continue\n",
        "    print(name)\n",
        "\n",
        "    annotated_image = image.copy()\n",
        "    for face_landmarks in results.multi_face_landmarks:\n",
        "       height, width, _ = annotated_image.shape\n",
        "       x1 = (int(face_landmarks.landmark[103].x * width), int(face_landmarks.landmark[103].y * height))\n",
        "       x2 = [int(face_landmarks.landmark[333].x * width), int(face_landmarks.landmark[333].y * height)]\n",
        "       x3 = [int(face_landmarks.landmark[225].x * width), int(face_landmarks.landmark[225].y * height)]\n",
        "       x4 = (int(face_landmarks.landmark[445].x * width), int(face_landmarks.landmark[445].y * height))\n",
        "       #cv2.rectangle(annotated_image, x1, x4, (0, 0, 255), 2)\n",
        "       annotated_image = annotated_image[x1[1]:x4[1], x1[0]:x4[0], :]\n",
        "\n",
        "\n",
        "       gray = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2GRAY)\n",
        "       #gray = cv2.GaussianBlur(gray, (11,11), 0)\n",
        "       edged = cv2.Canny(gray, 50, 100)\n",
        "       edged = cv2.dilate(edged, None, iterations=1)\n",
        "       edged = cv2.erode(edged, None, iterations=1)\n",
        "\n",
        "       # find contours in the edge map\n",
        "       cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
        "\t        cv2.CHAIN_APPROX_SIMPLE)\n",
        "       cnts = imutils.grab_contours(cnts)\n",
        "      # sort the contours from left-to-right and initialize the\n",
        "      # 'pixels per metric' calibration variable\n",
        "      #(cnts, _) = contours.sort_contours(cnts)\n",
        "      #pixelsPerMetric = None\n",
        "\n",
        "\n",
        "       for c in cnts:\n",
        "\t      # if the contour is not sufficiently large, ignore it\n",
        "        if cv2.contourArea(c) < 100:\n",
        "\t\t        continue\n",
        "\t      # compute the rotated bounding box of the contour\n",
        "        orig = annotated_image.copy()\n",
        "        box = cv2.minAreaRect(c)\n",
        "        box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n",
        "        box = np.array(box, dtype=\"int\")\n",
        "        # order the points in the contour such that they appear\n",
        "        # in top-left, top-right, bottom-right, and bottom-left\n",
        "        # order, then draw the outline of the rotated bounding\n",
        "        # box\n",
        "        box = perspective.order_points(box)\n",
        "        cv2.drawContours(orig, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
        "        # loop over the original points and draw them\n",
        "        for (x, y) in box:\n",
        "          cv2.circle(orig, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
        "  \n",
        "    cv2.imwrite(output_dir + '/' + name, orig )   \n",
        "       \n",
        "       \n",
        "'''\n",
        "       mp_drawing.draw_landmarks(\n",
        "          image=annotated_image,\n",
        "          landmark_list=face_landmarks,\n",
        "          #connections=mp_face_mesh.FACE_CONNECTIONS,\n",
        "          landmark_drawing_spec=drawing_spec,\n",
        "          connection_drawing_spec=drawing_spec)\n",
        "      \n",
        "    #cv2_imshow(annotated_image)\n",
        "'''    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "_Jz5g7iuhmnN",
        "outputId": "2e534206-64d5-4845-9508-7c507d0ac076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Face landmarks of 20220528_174701.jpg:\n",
            "20220528_174701.jpg\n",
            "Face landmarks of 20220528_174728.jpg:\n",
            "20220528_174728.jpg\n",
            "Face landmarks of 20220528_174733.jpg:\n",
            "20220528_174733.jpg\n",
            "Face landmarks of 20220528_174737 (1).jpg:\n",
            "20220528_174737 (1).jpg\n",
            "Face landmarks of 20220528_174737.jpg:\n",
            "20220528_174737.jpg\n",
            "Face landmarks of 20220528_174740.jpg:\n",
            "20220528_174740.jpg\n",
            "Face landmarks of 20220528_174745.jpg:\n",
            "20220528_174745.jpg\n",
            "Face landmarks of 20220528_174747.jpg:\n",
            "20220528_174747.jpg\n",
            "Face landmarks of 20220528_174757.jpg:\n",
            "20220528_174757.jpg\n",
            "Face landmarks of 20220528_174801.jpg:\n",
            "20220528_174801.jpg\n",
            "Face landmarks of 20220528_174804.jpg:\n",
            "20220528_174804.jpg\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n       mp_drawing.draw_landmarks(\\n          image=annotated_image,\\n          landmark_list=face_landmarks,\\n          #connections=mp_face_mesh.FACE_CONNECTIONS,\\n          landmark_drawing_spec=drawing_spec,\\n          connection_drawing_spec=drawing_spec)\\n      \\n    #cv2_imshow(annotated_image)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}